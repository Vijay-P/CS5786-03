{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /home/vijay/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import sklearn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import string \n",
    "import nltk # import Natural Language Toolkit\n",
    "nltk.download('wordnet') # download the corpus of words the NLTK library uses\n",
    "from nltk.stem import WordNetLemmatizer # import the lemmatizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Input the file name as a string\n",
    "# Outputs two lists: [listOfReviews], [listOfLabels]\n",
    "def loadAndParse(inputFileName):\n",
    "    # Open file\n",
    "    fIn = open(inputFileName)\n",
    "\n",
    "    # split the the file into lines\n",
    "    lines = fIn.read().splitlines()\n",
    "\n",
    "    # Now split each line on tabs to get text and label\n",
    "    reviews = []\n",
    "    labels = []\n",
    "    for review in lines:\n",
    "        messageAndLabelList = review.split('\\t')\n",
    "        if(len(messageAndLabelList) != 2):\n",
    "            print(review)\n",
    "        message = messageAndLabelList[0]\n",
    "        label = messageAndLabelList[1]\n",
    "        reviews.append(message)\n",
    "        labels.append(label)\n",
    "    return reviews, labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Definitely worth seeing\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-4180dd83370f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Get three lists of reviews and three lists of labels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0myelpReviews\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myelpLabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloadAndParse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'sentiment_labelled_sentences/yelp_labelled.txt'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mimdbReviews\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimdbLabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloadAndParse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'sentiment_labelled_sentences/imdb_labelled.txt'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mamazonReviews\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mamazonLabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloadAndParse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'sentiment_labelled_sentences/amazon_cells_labelled.txt'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-21-55bef7092ba4>\u001b[0m in \u001b[0;36mloadAndParse\u001b[0;34m(inputFileName)\u001b[0m\n\u001b[1;32m     16\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreview\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmessageAndLabelList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m         \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmessageAndLabelList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m         \u001b[0mreviews\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "# Get three lists of reviews and three lists of labels\n",
    "yelpReviews, yelpLabels = loadAndParse('sentiment_labelled_sentences/yelp_labelled.txt')\n",
    "imdbReviews, imdbLabels = loadAndParse('sentiment_labelled_sentences/imdb_labelled.txt')\n",
    "amazonReviews, amazonLabels = loadAndParse('sentiment_labelled_sentences/amazon_cells_labelled.txt')\n",
    "\n",
    "# Make two big lists: one of all reviews and one of all labels, in matching order.\n",
    "allReviews = []\n",
    "allLabels = []\n",
    "allReviews = yelpReviews + imdbReviews + amazonReviews\n",
    "allLabels = yelpLabels + imdbLabels + amazonLabels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'amazonLabels' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-773361144fc7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Count the number of positive and negative reviews\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mamazon_positives\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mamazon_negatives\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mamazonLabels\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'amazonLabels' is not defined"
     ]
    }
   ],
   "source": [
    "# Count the number of positive and negative reviews\n",
    "amazon_positives , amazon_negatives = 0, 0\n",
    "for label in amazonLabels:\n",
    "    label = int(label)\n",
    "    if label == 1:\n",
    "        positives += 1\n",
    "    if label == 0:\n",
    "        negatives += 1\n",
    "    \n",
    "print(\"AMAZON: There are\", amazon_positives, \"positive reviews.\")\n",
    "print(\"AMAZON: There are\", amazon_negatives, \"negative reviews.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'imdbLabels' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-b9e56ef94073>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Count the number of positive and negative reviews\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mimdb_positives\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mimdb_negatives\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mimdbLabels\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'imdbLabels' is not defined"
     ]
    }
   ],
   "source": [
    "# Count the number of positive and negative reviews\n",
    "imdb_positives , imdb_negatives = 0, 0\n",
    "for label in imdbLabels:\n",
    "    label = int(label)\n",
    "    if label == 1:\n",
    "        positives += 1\n",
    "    if label == 0:\n",
    "        negatives += 1\n",
    "    \n",
    "print(\"IMDB: There are\", imdb_positives, \"positive reviews.\")\n",
    "print(\"IMDB: There are\", imdb_negatives, \"negative reviews.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Count the number of positive and negative reviews\n",
    "yelp_positives , yelp_negatives = 0, 0\n",
    "for label in yelpLabels:\n",
    "    label = int(label)\n",
    "    if label == 1:\n",
    "        positives += 1\n",
    "    if label == 0:\n",
    "        negatives += 1\n",
    "    \n",
    "print(\"YELP: There are\", yelp_positives, \"positive reviews.\")\n",
    "print(\"YELP: There are\", yelp_negatives, \"negative reviews.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 1500 positive reviews.\n",
      "There are 1500 negative reviews.\n"
     ]
    }
   ],
   "source": [
    "# Count the number of positive and negative reviews\n",
    "positives , negatives = 0, 0\n",
    "for label in allLabels:\n",
    "    label = int(label)\n",
    "    if label == 1:\n",
    "        positives += 1\n",
    "    if label == 0:\n",
    "        negatives += 1\n",
    "    \n",
    "print(\"There are\", positives, \"positive reviews.\")\n",
    "print(\"There are\", negatives, \"negative reviews.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# A working punctuation remover. It can do whole sentences.\n",
    "def stripPunctuation(input):\n",
    "    translation_table = dict.fromkeys(map(ord, '$#%&!()*+,-./:;<=>?@[\\]^_`{|}~'), None)\n",
    "    output = input.translate(translation_table)\n",
    "    # from: https://stackoverflow.com/questions/3939361/remove-specific-characters-from-a-string-in-python\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# A working word lemmatizer. It works on single words.\n",
    "def lemmatizeWord(input):\n",
    "    lemmatize = WordNetLemmatizer()\n",
    "    output = lemmatize.lemmatize(input)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# STEPS\n",
    "# 1) import each of the three files\n",
    "# 2) create a list of strings from each file, where each string is a message\n",
    "# 3) Clean each string: strip punctuation\n",
    "\n",
    "# 3b) Create training set and test set\n",
    "\n",
    "# 4) split each string into a list of individual words by splitting on spaces\n",
    "# 5) add the lists to make one big list of words \n",
    "# 6) lowercase and lemmatize every word in the list\n",
    "# 7) convert the list into a set to get rid of repeats. This set is the corpus.\n",
    "# 8) Maybe convert the set back into a list if that's needed to iterate over the list\n",
    "\n",
    "# ... remove stop words\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
